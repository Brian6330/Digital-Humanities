{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8 - Classification and Naive Bayes (part one)\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1: Consider the “sms-spam.csv” dataset. Preprocess this dataset by applying a stemming procedure and remove the stopwords contained in the “stopwords.txt” file\n",
    "General imports and solving the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import lxml.etree\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "np.random.seed(6)  # for reproducibility\n",
    "df = pd.read_csv('Data/federalist-papersNew2.csv', index_col=0)\n",
    "hamilton = df[df['AUTHOR'] == 'Hamilton']\n",
    "madison = df[df['AUTHOR'] == 'Madison']\n",
    "\n",
    "combined = pd.concat([hamilton, madison])\n",
    "test_indices = [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63]\n",
    "test_set = df.loc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essays where the author is known"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton    51\n",
      "Madison     14\n",
      "Name: AUTHOR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_known = df.loc[df['AUTHOR'].isin(('Hamilton', 'Madison'))]\n",
    "print(df_known['AUTHOR'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "hamilton_short = hamilton[['what','to', 'would']]\n",
    "madison_short = madison[['what','to', 'would']]\n",
    "combined_short = combined[['what','to', 'would']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estimate probability of each word in vocabulary being used by Hamilton"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.02574430823117338, 0.8029772329246935, 0.1628721541155867]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fH = []\n",
    "k = hamilton_short.sum(axis=0)\n",
    "total_sum = sum(k)\n",
    "for i in range(0, 3):\n",
    "    prob = ((k[i] + 1) / (float(total_sum + len(hamilton_short))))\n",
    "    fH.append(prob)\n",
    "fH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estimate probability of each word in vocabulary being used by Madison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.02979011509817197, 0.8544346648612051, 0.1083276912660799]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fM = []\n",
    "k = madison_short.sum(axis=0)\n",
    "total_sum = sum(k)\n",
    "for i in range(0, 3):\n",
    "    prob = ((k[i] + 1) / float(total_sum + len(madison_short)))\n",
    "    fM.append(prob)\n",
    "fM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute ratio of these probabilities ('what', 'to', 'would')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8641896194873427, 0.939776048359566, 1.5035135726795097]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fratio = [a / b for a, b in zip(fH, fM)]\n",
    "fratio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute prior probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7846153846153846"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piH = len(hamilton_short) / float(len(combined))\n",
    "piH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2153846153846154"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piM = len(madison_short) / float(len(combined))\n",
    "piM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we iterate over disputed sets and try to figure out which author to attribute them to"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.642857142857143\n",
      "3.4234698904527043\n",
      "3.642857142857143\n",
      "3.4234698904527043\n",
      "3.642857142857143\n",
      "3.642857142857143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h_count = 0\n",
    "m_count = 0\n",
    "for doc in range(0, len(test_set)):\n",
    "    # Compute likelihood ratio for Naive Bayes model\n",
    "    tmp = [np.power(a, b) for a, b in zip(fratio, test_set.iloc[doc])]\n",
    "    tmp = np.prod(np.array(tmp))\n",
    "    LR = tmp * (piH) / (piM)\n",
    "    print(LR)\n",
    "    if LR > 0.5:\n",
    "        h_count = h_count + 1\n",
    "        # print('Hamilton')\n",
    "    else:\n",
    "        m_count = m_count + 1\n",
    "        # print('Madison')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton papers: 12\n",
      "Madison papers: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Hamilton papers: \" + str(h_count))\n",
    "print(\"Madison papers: \" + str(m_count))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems like all disputed papers are attributed to Madison with this approach.\n",
    "\n",
    "I am slightly unhappy though, as LR has a value larger than 1, should this be possible? Might have made a mistake somewhere"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
