{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Probabilistic models\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1: Represent each play by a vector with only the tf component. You can apply some preprocessing before generating this vector representation.\n",
    "General imports and setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "498 498 498 498 208\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import lxml.etree\n",
    "import os\n",
    "from scipy import stats\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "import collections\n",
    "\n",
    "np.random.seed(6)  # for reproducibility\n",
    "\n",
    "PUNCT_RE = re.compile(r'[^\\w\\s]+$')\n",
    "\n",
    "\n",
    "def is_punct(string):\n",
    "    \"\"\"Check if STRING is a punctuation marker or a sequence of\n",
    "       punctuation markers.\n",
    "    \"\"\"\n",
    "    return PUNCT_RE.match(string) is not None\n",
    "\n",
    "def preprocess_text(text, language='French', lowercase=True):\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if (language == 'French'):\n",
    "        text = re.sub(\"-\", \" \", text)\n",
    "        text = re.sub(\"l'\", \"le \", text)\n",
    "        text = re.sub(\"d'\", \"de \", text)\n",
    "        text = re.sub(\"c'\", \"ce \", text)\n",
    "        text = re.sub(\"j'\", \"je \", text)\n",
    "        text = re.sub(\"m'\", \"me \", text)\n",
    "        text = re.sub(\"qu'\", \"que \", text)\n",
    "        text = re.sub(\"'\", \" ' \", text)\n",
    "        text = re.sub(\"quelqu'\", \"quelque \", text)\n",
    "        text = re.sub(\"aujourd'hui\", \"aujourdhui\", text)\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)\n",
    "    tokens = [token for token in tokens if not is_punct(token)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "subgenres = ('Comédie', 'Tragédie', 'Tragi-comédie')\n",
    "plays, titles, genres = [], [], []\n",
    "authors, years = [], []\n",
    "\n",
    "for fn in os.scandir('theatre-classique'):\n",
    "    # Only include XML files\n",
    "    if not fn.name.endswith('.xml'):\n",
    "        continue\n",
    "    tree   = lxml.etree.parse(fn.path)\n",
    "    genre  = tree.find('//genre')\n",
    "    title  = tree.find('//title')\n",
    "    author = tree.find('//author')\n",
    "    year   = tree.find('//date')\n",
    "    if genre is not None and genre.text in subgenres:\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays.append(text)\n",
    "        genres.append(genre.text)\n",
    "        titles.append(title.text)\n",
    "        authors.append(author.text)\n",
    "        if year is not None:\n",
    "            years.append(year.text)\n",
    "\n",
    "print (len(plays), len(genres), len(titles), len(authors), len(years))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Brian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "38410"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "plays_tok = [preprocess_text(play, 'French') for play in plays]\n",
    "\n",
    "def extract_vocabulary(tokenized_corpus, min_count=1, max_count=float('inf')):\n",
    "    vocabulary = collections.Counter()\n",
    "    for document in tokenized_corpus:\n",
    "        vocabulary.update(document)\n",
    "    vocabulary = {word for word, count in vocabulary.items()\n",
    "                  if count >= min_count and count <= max_count}\n",
    "    return sorted(vocabulary)\n",
    "\n",
    "vocabulary = extract_vocabulary(plays_tok, min_count=2)\n",
    "len(vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document-term matrix with |D| = 498 documents and |V| = 38410 words.\n"
     ]
    }
   ],
   "source": [
    "# Representation in a doc x term matrix for the French plays\n",
    "def corpus2dtm(tokenized_corpus, vocabulary):\n",
    "    \"Transform a tokenized corpus into a document-term matrix\"\n",
    "    document_term_matrix = []\n",
    "    for document in tokenized_corpus:\n",
    "        document_counts = collections.Counter(document)\n",
    "        row = [document_counts[word] for word in vocabulary]\n",
    "        document_term_matrix.append(row)\n",
    "    return document_term_matrix\n",
    "\n",
    "# building the doc/term matrix in a few seconds for the French example\n",
    "document_term_matrix = np.array(corpus2dtm(plays_tok, vocabulary))\n",
    "print(f\"document-term matrix with \"\n",
    "      f\"|D| = {document_term_matrix.shape[0]} documents and \"\n",
    "      f\"|V| = {document_term_matrix.shape[1]} words.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can calculate the tf component, which is the occurrence frequency of a term in the whole corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2: For each genre, it is possible to generate a “profile”, in the form of a single vector representing the entire set of plays corresponding to this genre. Build such a profile for each of the three genres (Comedy, Tragedy and Tragicomedy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plays_com, titles_com, genres_com = [], [], []\n",
    "authors_com, years_com = [], []\n",
    "\n",
    "plays_tra, titles_tra, genres_tra = [], [], []\n",
    "authors_tra, years_tra = [], []\n",
    "\n",
    "plays_tra_com, titles_tra_com, genres_tra_com = [], [], []\n",
    "authors_tra_com, years_tra_com = [], []\n",
    "for fn in os.scandir('theatre-classique'):\n",
    "    # Only include XML files\n",
    "    if not fn.name.endswith('.xml'):\n",
    "        continue\n",
    "    tree   = lxml.etree.parse(fn.path)\n",
    "    genre  = tree.find('//genre')\n",
    "    title  = tree.find('//title')\n",
    "    author = tree.find('//author')\n",
    "    year   = tree.find('//date')\n",
    "    if genre is not None and genre.text == 'Comédie':\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays_com.append(text)\n",
    "        genres_com.append(genre.text)\n",
    "        titles_com.append(title.text)\n",
    "        authors_com.append(author.text)\n",
    "        if year is not None:\n",
    "            years_com.append(year.text)\n",
    "    elif genre is not None and genre.text == 'Tragédie':\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays_tra.append(text)\n",
    "        genres_tra.append(genre.text)\n",
    "        titles_tra.append(title.text)\n",
    "        authors_tra.append(author.text)\n",
    "        if year is not None:\n",
    "            years_tra.append(year.text)\n",
    "    elif genre is not None and genre.text == 'Tragi-comédie':\n",
    "        lines = []\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "        text = '\\n'.join(lines)\n",
    "        plays_tra_com.append(text)\n",
    "        genres_tra_com.append(genre.text)\n",
    "        titles_tra_com.append(title.text)\n",
    "        authors_tra_com.append(author.text)\n",
    "        if year is not None:\n",
    "            years_tra_com.append(year.text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3: How many terms with a weight strictly larger than 0 do you have in each text genre profile?\n",
    "\n",
    "Her we will use the TF IDF for the weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition says this should simply be 1'000?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4: Select randomly 10 plays for each text genre. Represent each play by a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamilton could resemble a Gaussian distribution, (centered around a length of 2250), but for Madison it does not really match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5: For each text genre and play, how many terms with a weight strictly larger than 0 do you have in the vector?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q6: For each text genre and play, how many terms with a weight strictly equal to 1 do you have in the vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
