{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Statistics and tests\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q1: Consider the sentence “Ann plays the role with Mary and Annie”. Use RegExp to replace “Ann” by “Alice” and obtain “Alice plays the role with Mary and Annie”.\n",
    "General imports and solving the question:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice plays the role with Mary and Annie\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import lxml.etree\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "s1 = \"Ann plays the role with Mary and Annie\"\n",
    "replaced1 = re.sub(\"Ann \", \"Alice \", s1)\n",
    "print(replaced1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q2: Consider the sentence \"$99.99 to $87.80 or Fr. 75.50\". Use RegExp to remove the decimal part of prices and obtain \"$99 to $87 or Fr. 75\".\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "s2 = \"$99.99 to $87.80 or Fr. 75.50\"\n",
    "replaced2 = re.sub('(\\d+)\\.\\d*', r'\\1', s2)\n",
    "print(replaced2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$99 to $87 or Fr. 75\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q3: For the genre “Comédie”, extract (in a list) the number of word-tokens per play. Do you obtain the same mean as the one indicated in the lecture slides (namely 9934.91 for 310 plays in this category)?\n",
    "\n",
    "Setup and solving the task"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'Comédie' work-tokens:  10042.429032258064\n"
     ]
    }
   ],
   "source": [
    "plays = {}\n",
    "counter = 0\n",
    "for xml_file in os.scandir('theatre-classique'):\n",
    "    tree = lxml.etree.parse(xml_file.path)\n",
    "    genre = tree.find('//genre')\n",
    "    lines = []\n",
    "    if genre is not None and genre.text == 'Comédie':\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "            text = ' '.join(lines)\n",
    "        plays[counter] = [a.lower() for a in re.split(r'\\W+', text)]\n",
    "        counter += 1\n",
    "\n",
    "all_plays = [len(words) for words in plays.values()]\n",
    "distinct_plays = [len(set(words)) for words in plays.values()]\n",
    "print(\"Mean of 'Comédie' work-tokens: \", np.mean(all_plays))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, we are near the result, but not quite. It could be that there are some encoding  issues that led to some malformed words.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q4: Apply the t-test to verify the hypothesis that, in mean, a French comedy contains 10,000 word-tokens."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-Value for French comedy containing 10'000 words: 0.8874058267073174\n"
     ]
    }
   ],
   "source": [
    "t_test_comedie_10000 = stats.ttest_1samp(all_plays, 10000)\n",
    "print(\"p-Value for French comedy containing 10'000 words:\", t_test_comedie_10000.pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The p-value is high, giving a likelihood of about 88% that our data fits the hypothesis of having 10'000 words on average. To reject the null-hypothesis, we would normally go with a very low p-value of 0.05 or smaller."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q5: Apply the t-test to verify the hypothesis that, in mean, a French tragedy contains 14,000 word-tokens.\n",
    "\n",
    "This was done in exercise 2 (the last series), thus I assume this is a mistake as we only have one author here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'Tragédie' work-tokens:  14326.026666666667\n",
      "p-Value for French tragedies containing 14'000 words: 0.24197018702608467\n"
     ]
    }
   ],
   "source": [
    "tragedies = {}\n",
    "counter = 0\n",
    "for xml_file in os.scandir('theatre-classique'):\n",
    "    tree = lxml.etree.parse(xml_file.path)\n",
    "    genre = tree.find('//genre')\n",
    "    lines = []\n",
    "    if genre is not None and genre.text == 'Tragédie':\n",
    "        for line in tree.xpath('//l|//p'):\n",
    "            lines.append(' '.join(line.itertext()))\n",
    "            text = ' '.join(lines)\n",
    "        tragedies[counter] = [a.lower() for a in re.split(r'\\W+', text)]\n",
    "        counter += 1\n",
    "\n",
    "all_tragedies = [len(words) for words in tragedies.values()]\n",
    "distinct_plays = [len(set(words)) for words in tragedies.values()]\n",
    "print(\"Mean of 'Tragédie' work-tokens: \", np.mean(all_tragedies))\n",
    "\n",
    "t_test_tragedies_14000 = stats.ttest_1samp(all_tragedies, 14000)\n",
    "print(\"p-Value for French tragedies containing 14'000 words:\", t_test_tragedies_14000.pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we have a lower p-value, the null-hypothesis is unlikelier than before, but normally we would only accept the alternative hypothesis at a significance level of 0.05 or lower."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q6: Apply the t-test to verify the hypothesis that, in mean, a French tragedy contains 15,000 word-tokens.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-Value for French tragedies containing 15'000 words: 0.016353531252481648\n"
     ]
    }
   ],
   "source": [
    "t_test_tragedies_15000 = stats.ttest_1samp(all_tragedies, 15000)\n",
    "print(\"p-Value for French tragedies containing 15'000 words:\", t_test_tragedies_15000.pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we have a p-value below 0.05, thus we accept the alternative hypothesis that the mean is unlikely to be 15'000 for french tragedies, based on this data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q7: Describe the results you obtained from the previous tests.\n",
    "\n",
    "This was already done at Q4, Q5, and Q6.\n",
    "\n",
    "Namely, in a normal case, we would stick with the null-hypothesis in Q4 and Q5, but in Q6, with such a low p-value, we would accept the alternative hypothesis: \"The mean words of tragedies within French plays is unlikely to be 15'000\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Q8: Apply the chi^2 test to verify the hypothesis that the distribution of the education level in the New England region is similar to the one appearing in the Pacific area.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value is:  0.05103567823078395\n",
      "chi=9.438059, critical value=9.487729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "with gzip.open('data/GSS7214_R5.DTA.gz', 'rb') as infile:\n",
    "    # we restrict this (very large) dataset to the variables of interest\n",
    "    columns = ['id', 'year', 'age', 'sex', 'race', 'reg16', 'degree',\n",
    "               'realrinc', 'readfict']\n",
    "    df = pd.read_stata(infile, columns=columns)\n",
    "\n",
    "regions_oi = sorted(['new england', 'pacific'])\n",
    "df_regions = df.loc[df['reg16'].isin(regions_oi)].copy()\n",
    "df_regions['reg16'] = df_regions['reg16'].cat.remove_unused_categories()\n",
    "df_regions.groupby('reg16')['degree'].value_counts(normalize=True).round(1).to_frame()\n",
    "df_regions.groupby('reg16')['degree'].value_counts().to_frame()\n",
    "\n",
    "subjects = pd.DataFrame(\n",
    "    [\n",
    "        # Original:\n",
    "        # [134, 120, 152, 318],\n",
    "        # [80, 72, 69, 112],\n",
    "        # [63, 34, 20, 63],\n",
    "        # [57, 19, 19, 48],\n",
    "        # [32, 17, 16, 42],\n",
    "\n",
    "        # Then removing the first and third column, as those were \"foreign\" and \"mountain\"\n",
    "        [120, 318],\n",
    "        [72, 112],\n",
    "        [34, 63],\n",
    "        [19, 48],\n",
    "        [17, 42],\n",
    "    ],\n",
    "    index=['high school', 'bachelor', 'graduate', 'lt high school', 'junior college'],\n",
    "    columns=['new england', 'pacific'])\n",
    "\n",
    "chi, pval, dof, exp = stats.chi2_contingency(subjects)\n",
    "print('p-value is: ', pval)\n",
    "\n",
    "significance = 0.05\n",
    "p = 1 - significance\n",
    "critical_value = stats.chi2.ppf(p, dof)\n",
    "print('chi=%.6f, critical value=%.6f\\n' % (chi, critical_value))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the Chi-square value is greater than or equal to the critical value:\n",
    "There is a significant difference between the groups, probably too great to be attributed to chance.\n",
    "\n",
    "If the Chi-square value is less than the critical value:\n",
    "There is no significant difference, it is likely  due to chance.\n",
    "\n",
    "Thus, as we have a value that is just barely less than the critical value, we can assume that the difference in distribution of the education level is due to chance.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
